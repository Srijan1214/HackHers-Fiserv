{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37364bitbasecondaccb0c1180edc481782339d9fb6e461e1",
   "display_name": "Python 3.7.3 64-bit ('base': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "(30000, 24)\n"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "df=pd.read_excel(\"D:/College\\Machine Learning/heckhers credit card default prediction/default of credit card clients.xls\")\n",
    "df=df.drop(index=0)\n",
    "df=df.drop(df.columns[0],axis=1)\n",
    "print(df.shape)\n",
    "df.head(5)\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alter the dataframe\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "df=df_scaled=pd.DataFrame(scaler.fit_transform(df),columns=df.columns)\n",
    "df_scaled.head(12)\n",
    "df=df.sort_values(by=['Y'])\n",
    "\n",
    "# df = df.tail(13200)\n",
    "df=df.sample(frac=1)\n",
    "\n",
    "X = df.drop('Y',1)\n",
    "y = df['Y']\n",
    "df=df.drop(df.columns[-1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)\n",
    "\n",
    "import numpy as np\n",
    "X_train = np.reshape(X_train.values,(len(X_train),(X_train.shape[1]),1))\n",
    "X_test = np.reshape(X_test.values,(len(X_test),(X_train.shape[1]),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Old Number of Features\n23\n"
    }
   ],
   "source": [
    "print(\"Old Number of Features\")\n",
    "print(X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce the number of feature given the p-value\n",
    "\n",
    "import statsmodels.regression.linear_model as sm\n",
    "def backwardElimination(x, Y, sl):\n",
    "    x = np.array(x, dtype=float)\n",
    "    numVars = len(x[0])\n",
    "    for i in range(0, numVars):\n",
    "        regressor_OLS = sm.OLS(Y, x).fit()\n",
    "        maxVar = max(regressor_OLS.pvalues)\n",
    "        if maxVar > sl:\n",
    "            for j in range(0, numVars - i):\n",
    "                if (regressor_OLS.pvalues[j].astype(float) == maxVar):\n",
    "                    x = np.delete(x, j, 1)\n",
    "                    \n",
    "    regressor_OLS.summary()\n",
    "    return x\n",
    "\n",
    "SL = 0.05\n",
    "data_modeled = backwardElimination(X, y,SL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Number of Features after Dimentionality Redection\n15\n"
    }
   ],
   "source": [
    "print(\"Number of Features after Dimentionality Redection\")\n",
    "print(data_modeled.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_modeled,y,test_size=0.2)\n",
    "\n",
    "import numpy as np\n",
    "X_train = np.reshape(X_train,(len(X_train),data_modeled.shape[1],1))\n",
    "X_test = np.reshape(X_test,(len(X_test),data_modeled.shape[1],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(24000, 15, 1)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Logistic Regression using sklearn\nTraining Accuracy: 0.8116666666666666\nTesting Accuracy: 0.8135\nR2 score: -0.10814479824717038\n"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "poly = PolynomialFeatures(2)\n",
    "\n",
    "temp_x_train = np.reshape(X_train,(len(X_train),15))\n",
    "temp_y_train = np.reshape(y_train,(len(y_train)))\n",
    "\n",
    "temp_x_test = np.reshape(X_test,(len(X_test),15))\n",
    "temp_y_test = np.reshape(y_test,(len(y_test)))\n",
    "\n",
    "sel = VarianceThreshold(threshold=.01)\n",
    "\n",
    "sel.fit(temp_x_train)\n",
    "\n",
    "\n",
    "temp_x_train  \n",
    "\n",
    "reg = LogisticRegression().fit(poly.fit_transform(temp_x_train), temp_y_train)\n",
    "\n",
    "\n",
    "reg.intercept_\n",
    "y_predict= reg.predict(poly.fit_transform(temp_x_test))\n",
    "print(\"Logistic Regression using sklearn\")\n",
    "print(\"Training Accuracy: \"+ str(reg.score(poly.fit_transform(temp_x_train),temp_y_train)))\n",
    "print(\"Testing Accuracy: \"+ str(reg.score(poly.fit_transform(temp_x_test),temp_y_test)))\n",
    "\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "print(\"R2 score: \" + str(r2_score(temp_y_test,y_predict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(24000, 15, 1)"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Import Worked\nAbout to start estimator\nOutput layer\nTrain on 10560 samples\nEpoch 1/30\n10560/10560 [==============================] - 2s 159us/sample - loss: 0.6287 - accuracy: 0.6491\nEpoch 2/30\n10560/10560 [==============================] - 1s 68us/sample - loss: 0.6013 - accuracy: 0.6874\nEpoch 3/30\n10560/10560 [==============================] - 1s 66us/sample - loss: 0.5960 - accuracy: 0.6881\nEpoch 4/30\n10560/10560 [==============================] - 1s 66us/sample - loss: 0.5922 - accuracy: 0.6897\nEpoch 5/30\n10560/10560 [==============================] - 1s 73us/sample - loss: 0.5894 - accuracy: 0.6958\nEpoch 6/30\n10560/10560 [==============================] - 1s 65us/sample - loss: 0.5868 - accuracy: 0.6936\nEpoch 7/30\n10560/10560 [==============================] - 1s 69us/sample - loss: 0.5848 - accuracy: 0.6968\nEpoch 8/30\n10560/10560 [==============================] - 1s 63us/sample - loss: 0.5823 - accuracy: 0.6955\nEpoch 9/30\n10560/10560 [==============================] - 1s 73us/sample - loss: 0.5802 - accuracy: 0.6992\nEpoch 10/30\n10560/10560 [==============================] - 1s 66us/sample - loss: 0.5793 - accuracy: 0.6974\nEpoch 11/30\n10560/10560 [==============================] - 1s 63us/sample - loss: 0.5776 - accuracy: 0.6977\nEpoch 12/30\n10560/10560 [==============================] - 1s 71us/sample - loss: 0.5775 - accuracy: 0.6987\nEpoch 13/30\n10560/10560 [==============================] - 1s 65us/sample - loss: 0.5755 - accuracy: 0.6999\nEpoch 14/30\n10560/10560 [==============================] - 1s 69us/sample - loss: 0.5739 - accuracy: 0.6990\nEpoch 15/30\n10560/10560 [==============================] - 1s 70us/sample - loss: 0.5730 - accuracy: 0.7013\nEpoch 16/30\n10560/10560 [==============================] - 1s 68us/sample - loss: 0.5720 - accuracy: 0.7026\nEpoch 17/30\n10560/10560 [==============================] - 1s 72us/sample - loss: 0.5720 - accuracy: 0.7006\nEpoch 18/30\n10560/10560 [==============================] - 1s 69us/sample - loss: 0.5700 - accuracy: 0.6998\nEpoch 19/30\n10560/10560 [==============================] - 1s 78us/sample - loss: 0.5703 - accuracy: 0.7005\nEpoch 20/30\n10560/10560 [==============================] - 1s 70us/sample - loss: 0.5692 - accuracy: 0.7019\nEpoch 21/30\n10560/10560 [==============================] - 1s 72us/sample - loss: 0.5693 - accuracy: 0.7030\nEpoch 22/30\n10560/10560 [==============================] - 1s 72us/sample - loss: 0.5670 - accuracy: 0.7022\nEpoch 23/30\n10560/10560 [==============================] - 1s 70us/sample - loss: 0.5661 - accuracy: 0.7030\nEpoch 24/30\n10560/10560 [==============================] - 1s 65us/sample - loss: 0.5658 - accuracy: 0.7052\nEpoch 25/30\n10560/10560 [==============================] - 1s 68us/sample - loss: 0.5647 - accuracy: 0.7058\nEpoch 26/30\n10560/10560 [==============================] - 1s 73us/sample - loss: 0.5662 - accuracy: 0.7059\nEpoch 27/30\n10560/10560 [==============================] - 1s 69us/sample - loss: 0.5648 - accuracy: 0.7091\nEpoch 28/30\n10560/10560 [==============================] - 1s 68us/sample - loss: 0.5647 - accuracy: 0.7068\nEpoch 29/30\n10560/10560 [==============================] - 1s 71us/sample - loss: 0.5636 - accuracy: 0.7082\nEpoch 30/30\n10560/10560 [==============================] - 1s 70us/sample - loss: 0.5631 - accuracy: 0.7060\n"
    }
   ],
   "source": [
    "#trying the reduced features on a neural network with convolutional layers\n",
    "\n",
    "from tensorflow.python.keras.layers import Dense,Dropout, Conv1D, MaxPool1D, GlobalMaxPooling1D,Embedding\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras import regularizers\n",
    "from sklearn.model_selection import cross_val_score\n",
    "#import keras_metrics\n",
    "print(\"Import Worked\")\n",
    "def create_model():\n",
    "    model=Sequential()\n",
    "    model.add(Conv1D(250, 8, padding = 'valid', activation=\"relu\", input_shape=(14,1)))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dense(30-1, activation='relu'))\n",
    "    model.add(Dense(30, activation='relu'))\n",
    "    model.add(Dense(2,activation=\"softmax\"))\n",
    "    \n",
    "    #COMPILE MODE\n",
    "    print(\"Output layer\")\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='nadam',metrics=[\"accuracy\"])\n",
    "    return model\n",
    " \n",
    "from tensorflow.python.keras.wrappers.scikit_learn import KerasClassifier\n",
    "print(\"About to start estimator\")   \n",
    "\n",
    "keras_model = create_model()\n",
    "history = keras_model.fit(X_train,y_train,epochs=30, batch_size=50,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "2640/2640 [==============================] - 0s 80us/sample - loss: 0.5654 - accuracy: 0.7095\n"
    }
   ],
   "source": [
    "#testing the accuracy\n",
    "test_loss,test_acc = keras_model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "86\nEpoch 120/300\n10560/10560 [==============================] - 1s 66us/sample - loss: 0.5302 - accuracy: 0.7262\nEpoch 121/300\n10560/10560 [==============================] - 1s 62us/sample - loss: 0.5292 - accuracy: 0.7267\nEpoch 122/300\n10560/10560 [==============================] - 1s 61us/sample - loss: 0.5304 - accuracy: 0.7255\nEpoch 123/300\n10560/10560 [==============================] - 1s 61us/sample - loss: 0.5294 - accuracy: 0.7260\nEpoch 124/300\n10560/10560 [==============================] - 1s 62us/sample - loss: 0.5283 - accuracy: 0.7280\nEpoch 125/300\n10560/10560 [==============================] - 1s 66us/sample - loss: 0.5297 - accuracy: 0.7259\nEpoch 126/300\n10560/10560 [==============================] - 1s 69us/sample - loss: 0.5276 - accuracy: 0.7289\nEpoch 127/300\n10560/10560 [==============================] - 1s 66us/sample - loss: 0.5266 - accuracy: 0.7318\nEpoch 128/300\n10560/10560 [==============================] - 1s 67us/sample - loss: 0.5271 - accuracy: 0.7310\nEpoch 129/300\n10560/10560 [==============================] - 1s 63us/sample - loss: 0.5257 - accuracy: 0.7263\nEpoch 130/300\n10560/10560 [==============================] - 1s 59us/sample - loss: 0.5263 - accuracy: 0.7277\nEpoch 131/300\n10560/10560 [==============================] - 1s 60us/sample - loss: 0.5269 - accuracy: 0.7276\nEpoch 132/300\n10560/10560 [==============================] - 1s 59us/sample - loss: 0.5279 - accuracy: 0.7267\nEpoch 133/300\n10560/10560 [==============================] - 1s 56us/sample - loss: 0.5270 - accuracy: 0.7268\nEpoch 134/300\n10560/10560 [==============================] - 1s 54us/sample - loss: 0.5249 - accuracy: 0.7266\nEpoch 135/300\n10560/10560 [==============================] - 1s 58us/sample - loss: 0.5232 - accuracy: 0.7337\nEpoch 136/300\n10560/10560 [==============================] - 1s 56us/sample - loss: 0.5248 - accuracy: 0.7297\nEpoch 137/300\n10560/10560 [==============================] - 1s 53us/sample - loss: 0.5244 - accuracy: 0.7298\nEpoch 138/300\n10560/10560 [==============================] - 1s 55us/sample - loss: 0.5229 - accuracy: 0.7314\nEpoch 139/300\n10560/10560 [==============================] - 1s 55us/sample - loss: 0.5233 - accuracy: 0.7314\nEpoch 140/300\n10560/10560 [==============================] - 1s 55us/sample - loss: 0.5224 - accuracy: 0.7299\nEpoch 141/300\n10560/10560 [==============================] - 1s 54us/sample - loss: 0.5241 - accuracy: 0.7283\nEpoch 142/300\n10560/10560 [==============================] - 1s 55us/sample - loss: 0.5219 - accuracy: 0.7284\nEpoch 143/300\n10560/10560 [==============================] - 1s 57us/sample - loss: 0.5214 - accuracy: 0.7336\nEpoch 144/300\n10560/10560 [==============================] - 1s 59us/sample - loss: 0.5217 - accuracy: 0.7324\nEpoch 145/300\n10560/10560 [==============================] - 1s 54us/sample - loss: 0.5205 - accuracy: 0.7312\nEpoch 146/300\n10560/10560 [==============================] - 1s 56us/sample - loss: 0.5217 - accuracy: 0.7322\nEpoch 147/300\n10560/10560 [==============================] - 1s 56us/sample - loss: 0.5215 - accuracy: 0.7320\nEpoch 148/300\n10560/10560 [==============================] - 1s 57us/sample - loss: 0.5207 - accuracy: 0.7337\nEpoch 149/300\n10560/10560 [==============================] - 1s 58us/sample - loss: 0.5214 - accuracy: 0.7295\nEpoch 150/300\n10560/10560 [==============================] - 1s 56us/sample - loss: 0.5198 - accuracy: 0.7322\nEpoch 151/300\n10560/10560 [==============================] - 1s 56us/sample - loss: 0.5169 - accuracy: 0.7345\nEpoch 152/300\n10560/10560 [==============================] - 1s 61us/sample - loss: 0.5185 - accuracy: 0.7339\nEpoch 153/300\n10560/10560 [==============================] - 1s 53us/sample - loss: 0.5198 - accuracy: 0.7359\nEpoch 154/300\n10560/10560 [==============================] - 1s 53us/sample - loss: 0.5192 - accuracy: 0.7331\nEpoch 155/300\n10560/10560 [==============================] - 1s 57us/sample - loss: 0.5188 - accuracy: 0.7348\nEpoch 156/300\n10560/10560 [==============================] - 1s 58us/sample - loss: 0.5164 - accuracy: 0.7359\nEpoch 157/300\n10560/10560 [==============================] - 1s 57us/sample - loss: 0.5172 - accuracy: 0.7292\nEpoch 158/300\n10560/10560 [==============================] - 1s 58us/sample - loss: 0.5176 - accuracy: 0.7336\nEpoch 159/300\n10560/10560 [==============================] - 1s 58us/sample - loss: 0.5177 - accuracy: 0.7316\nEpoch 160/300\n10250/10560 [============================>.] - ETA: 0s - loss: 0.5148 - accuracy: 0.7310560/10560 [==============================] - 1s 56us/sample - loss: 0.5142 - accuracy: 0.7332\nEpoch 161/300\n10560/10560 [==============================] - 1s 57us/sample - loss: 0.5159 - accuracy: 0.7333\nEpoch 162/300\n10560/10560 [==============================] - 1s 51us/sample - loss: 0.5168 - accuracy: 0.7346\nEpoch 163/300\n10560/10560 [==============================] - 1s 52us/sample - loss: 0.5153 - accuracy: 0.7359\nEpoch 164/300\n10560/10560 [==============================] - 1s 53us/sample - loss: 0.5130 - accuracy: 0.7349\nEpoch 165/300\n10560/10560 [==============================] - 1s 55us/sample - loss: 0.5197 - accuracy: 0.7334\nEpoch 166/300\n10560/10560 [==============================] - 1s 54us/sample - loss: 0.5145 - accuracy: 0.7355\nEpoch 167/300\n10560/10560 [==============================] - 1s 56us/sample - loss: 0.5150 - accuracy: 0.7353\nEpoch 168/300\n10560/10560 [==============================] - 1s 55us/sample - loss: 0.5124 - accuracy: 0.7369\nEpoch 169/300\n10560/10560 [==============================] - 1s 58us/sample - loss: 0.5120 - accuracy: 0.7376\nEpoch 170/300\n10560/10560 [==============================] - 1s 53us/sample - loss: 0.5121 - accuracy: 0.7359\nEpoch 171/300\n10560/10560 [==============================] - 1s 55us/sample - loss: 0.5119 - accuracy: 0.7365\nEpoch 172/300\n10560/10560 [==============================] - 1s 54us/sample - loss: 0.5108 - accuracy: 0.7347\nEpoch 173/300\n10560/10560 [==============================] - 1s 55us/sample - loss: 0.5128 - accuracy: 0.7375\nEpoch 174/300\n10560/10560 [==============================] - 1s 56us/sample - loss: 0.5096 - accuracy: 0.7366\nEpoch 175/300\n10560/10560 [==============================] - 1s 58us/sample - loss: 0.5111 - accuracy: 0.7356\nEpoch 176/300\n10560/10560 [==============================] - 1s 57us/sample - loss: 0.5097 - accuracy: 0.7389\nEpoch 177/300\n10560/10560 [==============================] - 1s 57us/sample - loss: 0.5102 - accuracy: 0.7395\nEpoch 178/300\n10560/10560 [==============================] - 1s 58us/sample - loss: 0.5097 - accuracy: 0.7376\nEpoch 179/300\n10560/10560 [==============================] - 1s 56us/sample - loss: 0.5102 - accuracy: 0.7400\nEpoch 180/300\n10560/10560 [==============================] - 1s 54us/sample - loss: 0.5084 - accuracy: 0.7382\nEpoch 181/300\n10560/10560 [==============================] - 1s 57us/sample - loss: 0.5106 - accuracy: 0.7387\nEpoch 182/300\n10560/10560 [==============================] - 1s 57us/sample - loss: 0.5085 - accuracy: 0.7411\nEpoch 183/300\n10560/10560 [==============================] - 1s 56us/sample - loss: 0.5073 - accuracy: 0.7429\nEpoch 184/300\n10560/10560 [==============================] - 1s 56us/sample - loss: 0.5063 - accuracy: 0.7385\nEpoch 185/300\n10560/10560 [==============================] - 1s 62us/sample - loss: 0.5079 - accuracy: 0.7374\nEpoch 186/300\n10560/10560 [==============================] - 1s 67us/sample - loss: 0.5093 - accuracy: 0.7357\nEpoch 187/300\n10560/10560 [==============================] - 1s 60us/sample - loss: 0.5074 - accuracy: 0.7397\nEpoch 188/300\n10560/10560 [==============================] - 1s 56us/sample - loss: 0.5050 - accuracy: 0.7425\nEpoch 189/300\n10560/10560 [==============================] - 1s 52us/sample - loss: 0.5056 - accuracy: 0.7385\nEpoch 190/300\n10560/10560 [==============================] - 1s 55us/sample - loss: 0.5054 - accuracy: 0.7420\nEpoch 191/300\n10560/10560 [==============================] - 1s 54us/sample - loss: 0.5065 - accuracy: 0.7415\nEpoch 192/300\n10560/10560 [==============================] - 1s 54us/sample - loss: 0.5046 - accuracy: 0.7451\nEpoch 193/300\n10560/10560 [==============================] - 1s 59us/sample - loss: 0.5028 - accuracy: 0.7465\nEpoch 194/300\n10560/10560 [==============================] - 1s 63us/sample - loss: 0.5031 - accuracy: 0.7417\nEpoch 195/300\n10560/10560 [==============================] - 1s 56us/sample - loss: 0.5043 - accuracy: 0.7422\nEpoch 196/300\n10560/10560 [==============================] - 1s 58us/sample - loss: 0.5013 - accuracy: 0.7439\nEpoch 197/300\n10560/10560 [==============================] - 1s 59us/sample - loss: 0.5039 - accuracy: 0.7395\nEpoch 198/300\n10560/10560 [==============================] - 1s 57us/sample - loss: 0.5025 - accuracy: 0.7435\nEpoch 199/300\n10560/10560 [==============================] - 1s 56us/sample - loss: 0.5008 - accuracy: 0.7451\nEpoch 200/300\n10560/10560 [==============================] - 1s 55us/sample - loss: 0.5013 - accuracy: 0.7447\nEpoch 201/300\n10560/10560 [==============================] - 1s 52us/sample - loss: 0.5018 - accuracy: 0.7438\nEpoch 202/300\n10560/10560 [==============================] - 1s 54us/sample - loss: 0.5019 - accuracy: 0.7417\nEpoch 203/300\n10560/10560 [==============================] - 1s 58us/sample - loss: 0.4991 - accuracy: 0.7455\nEpoch 204/300\n10560/10560 [==============================] - 1s 54us/sample - loss: 0.5000 - accuracy: 0.7462\nEpoch 205/300\n10560/10560 [==============================] - 1s 56us/sample - loss: 0.4989 - accuracy: 0.7456\nEpoch 206/300\n10560/10560 [==============================] - 1s 57us/sample - loss: 0.4982 - accuracy: 0.7448\nEpoch 207/300\n10560/10560 [==============================] - 1s 59us/sample - loss: 0.5010 - accuracy: 0.7414\nEpoch 208/300\n10560/10560 [==============================] - 1s 56us/sample - loss: 0.5008 - accuracy: 0.7419\nEpoch 209/300\n10560/10560 [==============================] - 1s 55us/sample - loss: 0.4986 - accuracy: 0.7427\nEpoch 210/300\n10560/10560 [==============================] - 1s 54us/sample - loss: 0.4971 - accuracy: 0.7425\nEpoch 211/300\n10560/10560 [==============================] - 1s 58us/sample - loss: 0.5009 - accuracy: 0.7429\nEpoch 212/300\n10560/10560 [==============================] - 1s 52us/sample - loss: 0.4969 - accuracy: 0.7426\nEpoch 213/300\n10560/10560 [==============================] - 1s 53us/sample - loss: 0.4967 - accuracy: 0.7466\nEpoch 214/300\n10560/10560 [==============================] - 1s 54us/sample - loss: 0.4966 - accuracy: 0.7429\nEpoch 215/300\n10560/10560 [==============================] - 1s 56us/sample - loss: 0.4947 - accuracy: 0.7461\nEpoch 216/300\n10560/10560 [==============================] - 1s 54us/sample - loss: 0.4966 - accuracy: 0.7430\nEpoch 217/300\n10560/10560 [==============================] - 1s 54us/sample - loss: 0.4959 - accuracy: 0.7474\nEpoch 218/300\n10560/10560 [==============================] - 1s 56us/sample - loss: 0.4953 - accuracy: 0.7447\nEpoch 219/300\n10560/10560 [==============================] - 1s 57us/sample - loss: 0.4983 - accuracy: 0.7437\nEpoch 220/300\n10560/10560 [==============================] - 1s 58us/sample - loss: 0.4968 - accuracy: 0.7461\nEpoch 221/300\n10560/10560 [==============================] - 1s 54us/sample - loss: 0.4926 - accuracy: 0.7475\nEpoch 222/300\n10560/10560 [==============================] - 1s 58us/sample - loss: 0.4937 - accuracy: 0.7445\nEpoch 223/300\n10560/10560 [==============================] - 1s 57us/sample - loss: 0.4927 - accuracy: 0.7484\nEpoch 224/300\n10560/10560 [==============================] - 1s 55us/sample - loss: 0.4950 - accuracy: 0.7454\nEpoch 225/300\n10560/10560 [==============================] - 1s 55us/sample - loss: 0.4915 - accuracy: 0.7495\nEpoch 226/300\n10560/10560 [==============================] - 1s 55us/sample - loss: 0.4944 - accuracy: 0.7429\nEpoch 227/300\n10560/10560 [==============================] - 1s 55us/sample - loss: 0.4920 - accuracy: 0.7483\nEpoch 228/300\n10560/10560 [==============================] - 1s 60us/sample - loss: 0.4914 - accuracy: 0.7515\nEpoch 229/300\n10560/10560 [==============================] - 1s 52us/sample - loss: 0.4880 - accuracy: 0.7513\nEpoch 230/300\n10560/10560 [==============================] - 1s 52us/sample - loss: 0.4921 - accuracy: 0.7491\nEpoch 231/300\n10560/10560 [==============================] - 1s 54us/sample - loss: 0.4910 - accuracy: 0.7496\nEpoch 232/300\n10560/10560 [==============================] - 1s 55us/sample - loss: 0.4921 - accuracy: 0.7487\nEpoch 233/300\n10560/10560 [==============================] - 1s 54us/sample - loss: 0.4894 - accuracy: 0.7467\nEpoch 234/300\n10560/10560 [==============================] - 1s 57us/sample - loss: 0.4909 - accuracy: 0.7485\nEpoch 235/300\n10560/10560 [==============================] - 1s 55us/sample - loss: 0.4889 - accuracy: 0.7486\nEpoch 236/300\n10560/10560 [==============================] - 1s 54us/sample - loss: 0.4882 - accuracy: 0.7510\nEpoch 237/300\n10560/10560 [==============================] - 1s 59us/sample - loss: 0.4892 - accuracy: 0.7492\nEpoch 238/300\n10560/10560 [==============================] - 1s 53us/sample - loss: 0.4897 - accuracy: 0.7465\nEpoch 239/300\n10560/10560 [==============================] - 1s 54us/sample - loss: 0.4888 - accuracy: 0.7488\nEpoch 240/300\n10560/10560 [==============================] - 1s 56us/sample - loss: 0.4878 - accuracy: 0.7514\nEpoch 241/300\n10560/10560 [==============================] - 1s 55us/sample - loss: 0.4861 - accuracy: 0.7507\nEpoch 242/300\n10560/10560 [==============================] - 1s 53us/sample - loss: 0.4840 - accuracy: 0.7556\nEpoch 243/300\n10560/10560 [==============================] - 1s 55us/sample - loss: 0.4876 - accuracy: 0.7497\nEpoch 244/300\n10560/10560 [==============================] - 1s 57us/sample - loss: 0.4862 - accuracy: 0.7522\nEpoch 245/300\n10560/10560 [==============================] - 1s 61us/sample - loss: 0.4847 - accuracy: 0.7498\nEpoch 246/300\n10560/10560 [==============================] - 1s 53us/sample - loss: 0.4848 - accuracy: 0.7500\nEpoch 247/300\n10560/10560 [==============================] - 1s 52us/sample - loss: 0.4866 - accuracy: 0.7509\nEpoch 248/300\n10560/10560 [==============================] - 1s 54us/sample - loss: 0.4869 - accuracy: 0.7498\nEpoch 249/300\n10560/10560 [==============================] - 1s 54us/sample - loss: 0.4856 - accuracy: 0.7532\nEpoch 250/300\n10560/10560 [==============================] - 1s 54us/sample - loss: 0.4839 - accuracy: 0.7509\nEpoch 251/300\n10560/10560 [==============================] - 1s 55us/sample - loss: 0.4848 - accuracy: 0.7538\nEpoch 252/300\n10560/10560 [==============================] - 1s 55us/sample - loss: 0.4837 - accuracy: 0.7514\nEpoch 253/300\n10560/10560 [==============================] - 1s 61us/sample - loss: 0.4802 - accuracy: 0.7582\nEpoch 254/300\n10560/10560 [==============================] - 1s 63us/sample - loss: 0.4841 - accuracy: 0.7535\nEpoch 255/300\n10560/10560 [==============================] - 1s 58us/sample - loss: 0.4833 - accuracy: 0.7550\nEpoch 256/300\n10560/10560 [==============================] - 1s 53us/sample - loss: 0.4802 - accuracy: 0.7528\nEpoch 257/300\n10560/10560 [==============================] - 1s 52us/sample - loss: 0.4850 - accuracy: 0.7549\nEpoch 258/300\n10560/10560 [==============================] - 1s 52us/sample - loss: 0.4810 - accuracy: 0.7509\nEpoch 259/300\n10560/10560 [==============================] - 1s 53us/sample - loss: 0.4819 - accuracy: 0.7545\nEpoch 260/300\n10560/10560 [==============================] - 1s 54us/sample - loss: 0.4823 - accuracy: 0.7545\nEpoch 261/300\n10560/10560 [==============================] - 1s 54us/sample - loss: 0.4780 - accuracy: 0.7591\nEpoch 262/300\n10560/10560 [==============================] - 1s 59us/sample - loss: 0.4816 - accuracy: 0.7522\nEpoch 263/300\n10560/10560 [==============================] - 1s 56us/sample - loss: 0.4780 - accuracy: 0.7565\nEpoch 264/300\n10560/10560 [==============================] - 1s 54us/sample - loss: 0.4791 - accuracy: 0.7542\nEpoch 265/300\n10560/10560 [==============================] - 1s 56us/sample - loss: 0.4798 - accuracy: 0.7563\nEpoch 266/300\n10560/10560 [==============================] - 1s 54us/sample - loss: 0.4756 - accuracy: 0.7596\nEpoch 267/300\n10560/10560 [==============================] - 1s 56us/sample - loss: 0.4791 - accuracy: 0.7521\nEpoch 268/300\n10560/10560 [==============================] - 1s 58us/sample - loss: 0.4782 - accuracy: 0.7570\nEpoch 269/300\n10560/10560 [==============================] - 1s 56us/sample - loss: 0.4773 - accuracy: 0.7577\nEpoch 270/300\n10560/10560 [==============================] - 1s 57us/sample - loss: 0.4772 - accuracy: 0.7548\nEpoch 271/300\n10560/10560 [==============================] - 1s 59us/sample - loss: 0.4795 - accuracy: 0.7559\nEpoch 272/300\n10560/10560 [==============================] - 1s 52us/sample - loss: 0.4762 - accuracy: 0.7598\nEpoch 273/300\n10560/10560 [==============================] - 1s 52us/sample - loss: 0.4750 - accuracy: 0.7587\nEpoch 274/300\n10560/10560 [==============================] - 1s 52us/sample - loss: 0.4754 - accuracy: 0.7595\nEpoch 275/300\n10560/10560 [==============================] - 1s 53us/sample - loss: 0.4740 - accuracy: 0.7579\nEpoch 276/300\n10560/10560 [==============================] - 1s 54us/sample - loss: 0.4775 - accuracy: 0.7556\nEpoch 277/300\n10560/10560 [==============================] - 1s 55us/sample - loss: 0.4746 - accuracy: 0.7589\nEpoch 278/300\n10560/10560 [==============================] - 1s 59us/sample - loss: 0.4751 - accuracy: 0.7579\nEpoch 279/300\n10560/10560 [==============================] - 1s 56us/sample - loss: 0.4765 - accuracy: 0.7541\nEpoch 280/300\n10560/10560 [==============================] - 1s 55us/sample - loss: 0.4706 - accuracy: 0.7615\nEpoch 281/300\n10560/10560 [==============================] - 1s 55us/sample - loss: 0.4746 - accuracy: 0.7587\nEpoch 282/300\n10560/10560 [==============================] - 1s 54us/sample - loss: 0.4710 - accuracy: 0.7638\nEpoch 283/300\n10560/10560 [==============================] - 1s 55us/sample - loss: 0.4700 - accuracy: 0.7619\nEpoch 284/300\n10560/10560 [==============================] - 1s 54us/sample - loss: 0.4718 - accuracy: 0.7580\nEpoch 285/300\n10560/10560 [==============================] - 1s 54us/sample - loss: 0.4709 - accuracy: 0.7599\nEpoch 286/300\n10560/10560 [==============================] - 1s 56us/sample - loss: 0.4731 - accuracy: 0.7585\nEpoch 287/300\n10560/10560 [==============================] - 1s 57us/sample - loss: 0.4728 - accuracy: 0.7607\nEpoch 288/300\n10560/10560 [==============================] - 1s 62us/sample - loss: 0.4694 - accuracy: 0.7607\nEpoch 289/300\n10560/10560 [==============================] - 1s 54us/sample - loss: 0.4691 - accuracy: 0.7632\nEpoch 290/300\n10560/10560 [==============================] - 1s 53us/sample - loss: 0.4734 - accuracy: 0.7580\nEpoch 291/300\n10560/10560 [==============================] - 1s 71us/sample - loss: 0.4680 - accuracy: 0.7641\nEpoch 292/300\n10560/10560 [==============================] - 1s 63us/sample - loss: 0.4699 - accuracy: 0.7628\nEpoch 293/300\n10560/10560 [==============================] - 1s 60us/sample - loss: 0.4699 - accuracy: 0.7636\nEpoch 294/300\n10560/10560 [==============================] - 1s 60us/sample - loss: 0.4686 - accuracy: 0.7634\nEpoch 295/300\n10560/10560 [==============================] - 1s 84us/sample - loss: 0.4691 - accuracy: 0.7601\nEpoch 296/300\n10560/10560 [==============================] - 1s 76us/sample - loss: 0.4673 - accuracy: 0.7672\nEpoch 297/300\n10560/10560 [==============================] - 1s 72us/sample - loss: 0.4673 - accuracy: 0.7631\nEpoch 298/300\n10560/10560 [==============================] - 1s 83us/sample - loss: 0.4653 - accuracy: 0.7666\nEpoch 299/300\n10560/10560 [==============================] - 1s 101us/sample - loss: 0.4675 - accuracy: 0.7624\nEpoch 300/300\n10560/10560 [==============================] - 1s 71us/sample - loss: 0.4682 - accuracy: 0.7623\n"
    },
    {
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x21230c0ac18>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_model.fit(X_train,y_train,epochs=300, batch_size=50,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "2640/2640 [==============================] - 0s 56us/sample - loss: 0.6696 - accuracy: 0.6814\n"
    }
   ],
   "source": [
    "test_loss,test_acc = keras_model.evaluate(X_test,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}